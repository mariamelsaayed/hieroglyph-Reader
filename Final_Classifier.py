# -*- coding: utf-8 -*-
"""classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u0jKpwIQOphKo5tskPFtLN-1DMsYkAxJ
"""

import pandas as pd 
import cv2 
import tensorflow as tf
from matplotlib import pyplot as plt
import numpy as np
from numpy import genfromtxt
from tensorflow.keras.models import load_model
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

tf.compat.v1.logging
print('Using TensorFlow version', tf.__version__)


def get_key(val,my_dict): 
    for key, value in my_dict.items(): 
         if val == value: 
             return key 
  
    return 'unknown'

# %matplotlib inline
#####READING TRAINING IMAGES TO TRAIN THE MODEL, X_train is a set of gray images and Y_train list of Gardiner Labels
#Labels has to be converted to integers to use keras.to_categorical 

y_train = genfromtxt('/content/y_train.csv', delimiter=',',dtype=str)
x_train = np.loadtxt('/content/x_train.txt').astype(int)

# Note that this returned a 2D array!

print( x_train.shape)
x_train = x_train.reshape((3584,75,50))

##find the set of labels in training set and create dictionary to map it to integers
set_list =sorted(set(y_train))

keys = np.arange(1, 171, 1).tolist()

label_dict = dict(zip(keys,set_list))

##Label list translated to integers
y_train_key = np.zeros((3584,)).astype(int)
for i in range(len(y_train)):
  y_train_key[i]=(get_key(y_train[i],label_dict))
##### End of reading training data 

##Split data to Train and Test
X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train_key, test_size=0.2)

#Reshape images 3d array to 2d array to feed it to neural network
x_train_reshaped=np.reshape(X_train,(2867,3750))
x_test_reshaped=np.reshape(X_test,(717,3750))


#Normalization of X_set
x_mean = np.mean(x_train_reshaped)
x_std = np.std(x_train_reshaped)
epsilon = 1e-10
x_train_norm = (x_train_reshaped-x_mean) / (x_std + epsilon)
x_test_norm = (x_test_reshaped-x_mean)/(x_std+epsilon)

##Encode Y_set 
y_train_encoded = to_categorical(Y_train)
y_test_encoded= to_categorical(Y_test)


##Create Model with input shape 3750 where all images have size (75x50)
#And output of 171 classes (Labels)
model = Sequential([
    Dense(128,activation='relu',input_shape=(3750,)),
    Dense(128,activation='relu'),
    Dense(171,activation='softmax')
])

model.compile(optimizer='sgd',
              loss='categorical_crossentropy',
              metrics=['accuracy']
             )
model.summary()

model.fit(x_train_norm,y_train_encoded,epochs=5)
model.save('model',save_format='h5')

loss,accuracy=model.evaluate(x_test_norm,y_test_encoded)
print('test set accuracu',accuracy*100)

preds = model.predict(x_test_norm)
##show predictions
plt.figure(figsize=(12,12))
start_index=0
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    
    pred=np.argmax(preds[start_index+i])
    label_pred = label_dict[pred]

    gt = label_dict[Y_test[start_index+i]]
    col='g'
    if label_pred != gt:
        col='r'
    plt.xlabel('i={},pred={},gt={}'.format(start_index+i,label_pred,gt),color=col)
    plt.imshow(X_test[start_index+i],cmap='binary')
plt.show()


#Save Dictionary
np.save('label_dict.npy', label_dict) 


